/**
 * å›¾ç‰‡ç±»å‹æ£€æµ‹å·¥å…·
 * æ ¹æ®åˆ†è¾¨ç‡å’Œå®½é«˜æ¯”è‡ªåŠ¨åˆ¤æ–­å£çº¸ç±»å‹
 */

/**
 * å£çº¸ç±»å‹æ£€æµ‹è§„åˆ™
 */
const DETECTION_RULES = {
  desktop: {
    // æ¡Œé¢å£çº¸ï¼šå®½åº¦ > é«˜åº¦ï¼Œä¸”å®½åº¦è¾ƒå¤§
    minWidth: 1280,
    aspectRatioRange: [1.3, 3.5], // å®½é«˜æ¯”èŒƒå›´ (16:9 â‰ˆ 1.78, 21:9 â‰ˆ 2.33)
    commonResolutions: [
      { width: 1920, height: 1080, name: '1080p (16:9)' },
      { width: 2560, height: 1440, name: '2K (16:9)' },
      { width: 3840, height: 2160, name: '4K (16:9)' },
      { width: 2560, height: 1080, name: '21:9 è¶…å®½' },
      { width: 3440, height: 1440, name: '21:9 2K' }
    ]
  },
  mobile: {
    // æ‰‹æœºå£çº¸ï¼šé«˜åº¦ > å®½åº¦ï¼Œä¸”é«˜åº¦è¾ƒå¤§
    minHeight: 1280,
    aspectRatioRange: [0.4, 0.75], // å®½é«˜æ¯”èŒƒå›´ (9:16 â‰ˆ 0.56, 9:19.5 â‰ˆ 0.46)
    commonResolutions: [
      { width: 1080, height: 1920, name: '1080x1920 (9:16)' },
      { width: 1080, height: 2340, name: '1080x2340 (9:19.5)' },
      { width: 1440, height: 3120, name: '1440x3120 (9:19.5)' },
      { width: 1284, height: 2778, name: 'iPhone 13 Pro' },
      { width: 1170, height: 2532, name: 'iPhone 12/13' }
    ]
  },
  avatar: {
    // å¤´åƒï¼šæ¥è¿‘æ­£æ–¹å½¢ï¼Œå°ºå¯¸è¾ƒå°
    maxSize: 1024,
    aspectRatioRange: [0.8, 1.25], // æ¥è¿‘ 1:1
    commonResolutions: [
      { width: 512, height: 512, name: '512x512' },
      { width: 1024, height: 1024, name: '1024x1024' },
      { width: 800, height: 800, name: '800x800' }
    ]
  }
}

/**
 * ä»æ–‡ä»¶ä¸­è¯»å–å›¾ç‰‡å°ºå¯¸
 * @param {File} file - å›¾ç‰‡æ–‡ä»¶
 * @returns {Promise<{width: number, height: number}>}
 */
export function getImageDimensions(file) {
  return new Promise((resolve, reject) => {
    // ç¡®ä¿åœ¨æµè§ˆå™¨ç¯å¢ƒä¸­
    if (typeof window === 'undefined' || typeof Image === 'undefined') {
      reject(new Error('æ­¤åŠŸèƒ½ä»…åœ¨æµè§ˆå™¨ç¯å¢ƒä¸­å¯ç”¨'))
      return
    }

    const img = new window.Image()
    const url = URL.createObjectURL(file)

    img.onload = () => {
      URL.revokeObjectURL(url)
      resolve({
        width: img.naturalWidth,
        height: img.naturalHeight
      })
    }

    img.onerror = () => {
      URL.revokeObjectURL(url)
      reject(new Error('æ— æ³•è¯»å–å›¾ç‰‡å°ºå¯¸'))
    }

    img.src = url
  })
}

/**
 * æ£€æµ‹å›¾ç‰‡ç±»å‹
 * @param {number} width - å›¾ç‰‡å®½åº¦
 * @param {number} height - å›¾ç‰‡é«˜åº¦
 * @returns {{type: string, confidence: number, reason: string, resolution: string}}
 */
export function detectImageType(width, height) {
  const aspectRatio = width / height
  const maxDimension = Math.max(width, height)

  // 1. æ£€æµ‹å¤´åƒï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼Œå› ä¸ºç‰¹å¾æœ€æ˜æ˜¾ï¼‰
  if (
    aspectRatio >= DETECTION_RULES.avatar.aspectRatioRange[0] &&
    aspectRatio <= DETECTION_RULES.avatar.aspectRatioRange[1] &&
    maxDimension <= DETECTION_RULES.avatar.maxSize
  ) {
    return {
      type: 'avatar',
      confidence: 0.95,
      reason: `æ¥è¿‘æ­£æ–¹å½¢ (${width}x${height})ï¼Œå°ºå¯¸è¾ƒå°ï¼Œåˆ¤å®šä¸ºå¤´åƒ`,
      resolution: `${width}x${height}`,
      aspectRatio: aspectRatio.toFixed(2)
    }
  }

  // 2. æ£€æµ‹æ¡Œé¢å£çº¸ï¼ˆæ¨ªå‘ï¼‰
  if (
    width > height &&
    width >= DETECTION_RULES.desktop.minWidth &&
    aspectRatio >= DETECTION_RULES.desktop.aspectRatioRange[0] &&
    aspectRatio <= DETECTION_RULES.desktop.aspectRatioRange[1]
  ) {
    // æŸ¥æ‰¾åŒ¹é…çš„å¸¸è§åˆ†è¾¨ç‡
    const matchedResolution = DETECTION_RULES.desktop.commonResolutions.find(
      res => Math.abs(res.width - width) < 50 && Math.abs(res.height - height) < 50
    )

    return {
      type: 'desktop',
      confidence: matchedResolution ? 0.98 : 0.9,
      reason: matchedResolution
        ? `åŒ¹é…å¸¸è§æ¡Œé¢åˆ†è¾¨ç‡ ${matchedResolution.name}`
        : `æ¨ªå‘å›¾ç‰‡ (${width}x${height})ï¼Œå®½é«˜æ¯” ${aspectRatio.toFixed(2)}ï¼Œåˆ¤å®šä¸ºæ¡Œé¢å£çº¸`,
      resolution: `${width}x${height}`,
      aspectRatio: aspectRatio.toFixed(2)
    }
  }

  // 3. æ£€æµ‹æ‰‹æœºå£çº¸ï¼ˆç«–å‘ï¼‰
  if (
    height > width &&
    height >= DETECTION_RULES.mobile.minHeight &&
    aspectRatio >= DETECTION_RULES.mobile.aspectRatioRange[0] &&
    aspectRatio <= DETECTION_RULES.mobile.aspectRatioRange[1]
  ) {
    // æŸ¥æ‰¾åŒ¹é…çš„å¸¸è§åˆ†è¾¨ç‡
    const matchedResolution = DETECTION_RULES.mobile.commonResolutions.find(
      res => Math.abs(res.width - width) < 50 && Math.abs(res.height - height) < 50
    )

    return {
      type: 'mobile',
      confidence: matchedResolution ? 0.98 : 0.9,
      reason: matchedResolution
        ? `åŒ¹é…å¸¸è§æ‰‹æœºåˆ†è¾¨ç‡ ${matchedResolution.name}`
        : `ç«–å‘å›¾ç‰‡ (${width}x${height})ï¼Œå®½é«˜æ¯” ${aspectRatio.toFixed(2)}ï¼Œåˆ¤å®šä¸ºæ‰‹æœºå£çº¸`,
      resolution: `${width}x${height}`,
      aspectRatio: aspectRatio.toFixed(2)
    }
  }

  // 4. è¾¹ç•Œæƒ…å†µå¤„ç†
  // 4.1 å°å°ºå¯¸æ­£æ–¹å½¢ -> å¤´åƒ
  if (
    aspectRatio >= 0.8 &&
    aspectRatio <= 1.25 &&
    maxDimension <= DETECTION_RULES.avatar.maxSize * 1.5
  ) {
    return {
      type: 'avatar',
      confidence: 0.8,
      reason: `æ¥è¿‘æ­£æ–¹å½¢ä¸”å°ºå¯¸é€‚ä¸­ (${width}x${height})ï¼Œå¯èƒ½æ˜¯å¤´åƒ`,
      resolution: `${width}x${height}`,
      aspectRatio: aspectRatio.toFixed(2)
    }
  }

  // 4.2 æ¨ªå‘ä½†å°ºå¯¸è¾ƒå° -> å¯èƒ½æ˜¯æ¡Œé¢å£çº¸
  if (width > height && aspectRatio >= 1.3) {
    return {
      type: 'desktop',
      confidence: 0.7,
      reason: `æ¨ªå‘å›¾ç‰‡ (${width}x${height})ï¼Œä½†åˆ†è¾¨ç‡è¾ƒä½ï¼Œå¯èƒ½æ˜¯æ¡Œé¢å£çº¸`,
      resolution: `${width}x${height}`,
      aspectRatio: aspectRatio.toFixed(2)
    }
  }

  // 4.3 ç«–å‘ä½†å°ºå¯¸è¾ƒå° -> å¯èƒ½æ˜¯æ‰‹æœºå£çº¸
  if (height > width && aspectRatio <= 0.75) {
    return {
      type: 'mobile',
      confidence: 0.7,
      reason: `ç«–å‘å›¾ç‰‡ (${width}x${height})ï¼Œä½†åˆ†è¾¨ç‡è¾ƒä½ï¼Œå¯èƒ½æ˜¯æ‰‹æœºå£çº¸`,
      resolution: `${width}x${height}`,
      aspectRatio: aspectRatio.toFixed(2)
    }
  }

  // 5. æ— æ³•åˆ¤æ–­ï¼Œé»˜è®¤ä¸ºæ¡Œé¢
  return {
    type: 'desktop',
    confidence: 0.5,
    reason: `æ— æ³•æ˜ç¡®åˆ¤æ–­ç±»å‹ (${width}x${height})ï¼Œé»˜è®¤ä¸ºæ¡Œé¢å£çº¸`,
    resolution: `${width}x${height}`,
    aspectRatio: aspectRatio.toFixed(2)
  }
}

/**
 * ä»æ–‡ä»¶è‡ªåŠ¨æ£€æµ‹å›¾ç‰‡ç±»å‹
 * @param {File} file - å›¾ç‰‡æ–‡ä»¶
 * @returns {Promise<{type: string, confidence: number, reason: string, resolution: string}>}
 */
export async function detectImageTypeFromFile(file) {
  const dimensions = await getImageDimensions(file)
  return detectImageType(dimensions.width, dimensions.height)
}

/**
 * æ‰¹é‡æ£€æµ‹å›¾ç‰‡ç±»å‹
 * @param {File[]} files - å›¾ç‰‡æ–‡ä»¶æ•°ç»„
 * @returns {Promise<Array<{file: File, detection: Object}>>}
 */
export async function detectBatchImageTypes(files) {
  const results = []

  for (const file of files) {
    try {
      const detection = await detectImageTypeFromFile(file)
      results.push({
        file,
        detection,
        fileName: file.name
      })
    } catch (error) {
      results.push({
        file,
        detection: {
          type: 'desktop',
          confidence: 0,
          reason: `æ£€æµ‹å¤±è´¥: ${error.message}`,
          resolution: 'unknown',
          aspectRatio: 'unknown'
        },
        fileName: file.name,
        error: error.message
      })
    }
  }

  return results
}

/**
 * è·å–æ£€æµ‹ç»Ÿè®¡ä¿¡æ¯
 * @param {Array} detectionResults - æ£€æµ‹ç»“æœæ•°ç»„
 * @returns {Object} ç»Ÿè®¡ä¿¡æ¯
 */
export function getDetectionStats(detectionResults) {
  const stats = {
    total: detectionResults.length,
    desktop: 0,
    mobile: 0,
    avatar: 0,
    highConfidence: 0, // confidence >= 0.9
    mediumConfidence: 0, // 0.7 <= confidence < 0.9
    lowConfidence: 0, // confidence < 0.7
    errors: 0
  }

  detectionResults.forEach(result => {
    if (result.error) {
      stats.errors++
      return
    }

    const { type, confidence } = result.detection

    // ç»Ÿè®¡ç±»å‹
    stats[type]++

    // ç»Ÿè®¡ç½®ä¿¡åº¦
    if (confidence >= 0.9) {
      stats.highConfidence++
    } else if (confidence >= 0.7) {
      stats.mediumConfidence++
    } else {
      stats.lowConfidence++
    }
  })

  return stats
}

/**
 * æ ¼å¼åŒ–æ£€æµ‹ç»“æœä¸ºå¯è¯»æ–‡æœ¬
 * @param {Object} detection - æ£€æµ‹ç»“æœ
 * @returns {string}
 */
export function formatDetectionResult(detection) {
  const typeNames = {
    desktop: 'ğŸ–¥ï¸ æ¡Œé¢å£çº¸',
    mobile: 'ğŸ“± æ‰‹æœºå£çº¸',
    avatar: 'ğŸ‘¤ å¤´åƒ'
  }

  const confidenceText =
    detection.confidence >= 0.9 ? 'é«˜' : detection.confidence >= 0.7 ? 'ä¸­' : 'ä½'

  return `${typeNames[detection.type]} (ç½®ä¿¡åº¦: ${confidenceText} ${(detection.confidence * 100).toFixed(0)}%)\n${detection.reason}`
}
